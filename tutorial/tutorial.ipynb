{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**# The overall algorithm:**\n",
    "\n",
    "\n",
    "    **1. Create embeddings of all cells.**\n",
    "    **2. Given a query, process the query to not have tonality and be specific.**\n",
    "    **3. Find the most similar to the query cells.**\n",
    "    **4. Filter excel with some additions on how to recover important cells.**\n",
    "    **5. Feed to llm a much smaller table with all noisy information omitted.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "attempted relative import with no known parent package",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[73], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mconcurrent\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfutures\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdata_formatting\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01magents\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# !pip3 install python-dotenv\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdotenv\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dotenv\n",
      "\u001b[0;31mImportError\u001b[0m: attempted relative import with no known parent package"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import sys\n",
    "import openpyxl\n",
    "import random\n",
    "import itertools\n",
    "import pandas as pd\n",
    "from pinecone import Pinecone\n",
    "from openpyxl import Workbook, load_workbook\n",
    "from openai import OpenAI\n",
    "import concurrent.futures\n",
    "from ..utils.data_formatting import *\n",
    "from ..utils.agents import *\n",
    "\n",
    "\n",
    "# !pip3 install python-dotenv\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the current working directory\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Construct the path to the .env file relative to the current directory\n",
    "env_path = os.path.join(current_dir, '..', '.env')\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv(env_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "SECRET_KEY = os.environ.get('SECRET_KEY')\n",
    "EMBED_API_KEY = os.environ.get('EMBED_API_KEY')\n",
    "PINECONE_API_KEY = os.environ.get('PINECONE_API_KEY')\n",
    "OPENROUTER_API_KEY = os.environ.get('OPENROUTER_API_KEY')\n",
    "EMBED_MODEL = os.environ.get('EMBED_MODEL')\n",
    "BASE_MODEL = os.environ.get('BASE_MODEL')\n",
    "INDEX_NAME = os.environ.get('INDEX_NAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "INDEX = pc.Index(INDEX_NAME)\n",
    "INDEX_DIMENSION = 1536"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each namespace in the index stores vectors; we will use one namespace per table. \n",
    "You can find more about namespaces at [pinecone.io](https://docs.pinecone.io/guides/getting-started/quickstart).\n",
    "\n",
    "Before pushing vectors to a namespace, clear the namespace so it has consists only of specified vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_namespace(namespace, index = INDEX):\n",
    "    # just add a single vector to the namespace, because \n",
    "    # deleting non-existing namespace will raise an error\n",
    "    index.upsert(\n",
    "    vectors=[\n",
    "        {\"id\": \"A\", \"values\": [0.1]*INDEX_DIMENSION},\n",
    "    ],\n",
    "    namespace=namespace,\n",
    "    )\n",
    "    index.delete(namespace = namespace, delete_all = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create embeddings concurrently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embeddings(terms, embed_model=EMBED_MODEL):\n",
    "    temp_client = OpenAI(api_key=EMBED_API_KEY)\n",
    "    def get_embedding(obj):\n",
    "        response = temp_client.embeddings.create(\n",
    "            input=obj['text_to_embed'],\n",
    "            model=embed_model,\n",
    "        )\n",
    "        embedding_vector = response.data[0].embedding\n",
    "        obj['values'] = embedding_vector\n",
    "        return obj\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        future_embeddings = [executor.submit(get_embedding, term) for term in terms]\n",
    "        results = [future.result() for future in concurrent.futures.as_completed(future_embeddings)]\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload (upsert) financial term objects to the pinecone in chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsert_chunks(terms, namespace, index=INDEX):\n",
    "    embeds = create_embeddings(terms)\n",
    "    new_embeds = []\n",
    "    for emb in embeds:\n",
    "        new_embeds.append({\"id\": emb[\"id\"], \n",
    "                           \"values\": emb[\"values\"], \n",
    "                           \"metadata\": {\n",
    "                                \"sheet\": emb[\"sheet\"],\n",
    "                                \"row\": emb[\"row\"],\n",
    "                                \"col\": emb[\"col\"],\n",
    "                                \"window_width\": emb[\"window_width\"],\n",
    "                                \"window_height\": emb[\"window_height\"],\n",
    "                                \"type\": emb[\"type\"]\n",
    "                                }   \n",
    "                        })\n",
    "\n",
    "    chunks = [new_embeds[i:i + 100] for i in range(0, len(new_embeds), 100)]\n",
    "\n",
    "    for chunk in chunks:\n",
    "        index.upsert(vectors=chunk, namespace=namespace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same but for `queries`, which have different representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsert_chunks_query(queries, namespace, index=INDEX):\n",
    "    embeds = create_embeddings(queries)\n",
    "    new_embeds = []\n",
    "    for emb in embeds:\n",
    "        new_embeds.append({\"id\": emb[\"id\"],\n",
    "                           \"values\": emb[\"values\"],   \n",
    "                        })\n",
    "\n",
    "    chunks = [new_embeds[i:i + 100] for i in range(0, len(new_embeds), 100)]\n",
    "\n",
    "    for chunk in chunks:\n",
    "        index.upsert(vectors=chunk, namespace=namespace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generates financial term embeddings from the given table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_fin_term_embeds(file_path):\n",
    "    def get_fin_terms_cell():\n",
    "        # Open the workbook with data_only=True to get the values instead of formulas\n",
    "        workbook = openpyxl.load_workbook(file_path, data_only=True)\n",
    "        terms = []\n",
    "        for sheet_name in workbook.sheetnames:\n",
    "            sheet = workbook[sheet_name]\n",
    "            \n",
    "            # Iterate over all cells in the current sheet\n",
    "            for row in sheet.iter_rows():\n",
    "                for term in row:\n",
    "                    common_data = {\n",
    "                        \"sheet\": sheet_name,\n",
    "                        \"row\": term.row,\n",
    "                        \"col\": term.column,\n",
    "                        \"window_width\": 0,\n",
    "                        \"window_height\": 0,\n",
    "                    }\n",
    "                    if term.value is None or isinstance(term.value, str) and not term.value.strip():\n",
    "                        continue\n",
    "                    text_to_embed = str(term.value)\n",
    "                    # print(f'{text_to_embed = }')\n",
    "                    if not text_to_embed.isnumeric():\n",
    "                        common_data.update({\"text_to_embed\": text_to_embed})\n",
    "                        common_data.update({\"type\": \"term\"})\n",
    "                    elif text_to_embed.isnumeric():\n",
    "                        # Find the first text cell to the left\n",
    "                        left_cell = term\n",
    "                        left_text = \"\"\n",
    "                        while left_cell.column > 1:\n",
    "                            left_cell = sheet.cell(row=left_cell.row, column=left_cell.column - 1)\n",
    "                            if isinstance(left_cell.value, str) and not left_cell.value.isnumeric():\n",
    "                                left_text = left_cell.value\n",
    "                                break\n",
    "\n",
    "                        up_cell = term\n",
    "                        up_text = \"\"\n",
    "                        while up_cell.row > 1:\n",
    "                            up_cell = sheet.cell(row=up_cell.row - 1, column=up_cell.column)\n",
    "                            if isinstance(up_cell.value, str):\n",
    "                                up_text = up_cell.value\n",
    "                                break\n",
    "                        text_to_embed = left_text + \" \" + up_text\n",
    "                        # print(f'Combined text to embed: {text_to_embed}')\n",
    "                        common_data.update({\"text_to_embed\": text_to_embed})\n",
    "                        common_data.update({\"type\": \"value\"})\n",
    "                    terms.append(common_data)\n",
    "        return terms\n",
    "    return get_fin_terms_cell()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embeddings(file_path):\n",
    "    new_namespace = file_path\n",
    "    clear_namespace(new_namespace, INDEX)\n",
    "\n",
    "    fin_term_embeds = generate_fin_term_embeds(file_path)  # Assume this function is defined elsewhere\n",
    "    # sliding_window_embeds = generate_sliding_window_emeds(file_path)  # Assume this function is defined elsewhere\n",
    "    combined_terms = fin_term_embeds #+ sliding_window_embeds\n",
    "    chunk_id = 1\n",
    "    for term in combined_terms:\n",
    "        term['id'] = str(chunk_id)\n",
    "        chunk_id +=1\n",
    "    upsert_chunks(combined_terms, file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gets top-k similar vectors for a given query. For larger tables top-k should be scaled accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similarities(query, namespace, index = INDEX, top_k=500, filter = None):\n",
    "    temp_client = OpenAI(\n",
    "    api_key=os.environ.get('EMBED_API_KEY'),\n",
    "    )\n",
    "\n",
    "    description_response = temp_client.embeddings.create(\n",
    "            input=query,\n",
    "            model=EMBED_MODEL,\n",
    "        )\n",
    "    query_embed_vec = description_response.data[0].embedding\n",
    "    if filter is None:\n",
    "        query = index.query(\n",
    "            namespace=namespace,\n",
    "            vector=query_embed_vec,\n",
    "            top_k=top_k,\n",
    "            include_metadata=True\n",
    "        )\n",
    "    else:\n",
    "        query = index.query(\n",
    "            namespace=namespace,\n",
    "            vector=query_embed_vec,\n",
    "            filter = filter,\n",
    "            top_k=top_k,\n",
    "            include_metadata=True\n",
    "        )\n",
    "    return query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_formatted_quiries(user_query):\n",
    "    filtered_query = FormatQuestionCall(user_query)\n",
    "    filtered_query.respond()\n",
    "    queries_formatted =  ({\"text_to_embed\": query, \"id\": str(ix+1)} for ix, query in enumerate(filtered_query.queries))\n",
    "    print(f'{filtered_query.queries = }')\n",
    "    return queries_formatted, filtered_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_quiries(queries_formatted):\n",
    "\n",
    "    new_namespace = \"QUERIES\"\n",
    "    clear_namespace(new_namespace, INDEX)\n",
    "    upsert_chunks_query(queries_formatted, \"QUERIES\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_single_query(query, table_path):\n",
    "        similarities = get_similarities(query, table_path, INDEX)\n",
    "\n",
    "        # create filtered table\n",
    "        # cell_set = create_similar_cell_set(similarities, threshold=0.2)\n",
    "        filtered_path = f\"filtered_table.xlsx\"\n",
    "        print(f'filtered excel for {table_path} is being created at {filtered_path}')\n",
    "\n",
    "        create_filtered_meta_excel(table_path, filtered_path, similarities)\n",
    "        # create_filtered_excel(table_path, filtered_path, cell_set)\n",
    "\n",
    "        answer_call = AnswerCall(query)\n",
    "        answer_call.load_table(filtered_path)\n",
    "        answer_call.respond()\n",
    "\n",
    "        query_result = answer_call.highlighted_json\n",
    "        return query_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_user_query(user_query, table_path):\n",
    "    queries_formatted, filtered_query = get_formatted_quiries(user_query)\n",
    "    embed_quiries(queries_formatted)\n",
    "\n",
    "    query_answers_list = []\n",
    "\n",
    "    for query in filtered_query.queries:\n",
    "        query_result = answer_single_query(query, table_path)\n",
    "        query_answers_list.append(query_result)\n",
    "       \n",
    "    return query_answers_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now load a table, and create embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'tutorial_data/sample_input.xlsx'\n",
    "generate_embeddings(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embeddings are now generated and stored in `filepath` namespace. \n",
    "\n",
    "Let's ask anything about this table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query = \"Revenue\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtered_query.queries = ['Total Revenue']\n",
      "filtered excel for tutorial_data/sample_input.xlsx is being created at filtered_table.xlsx\n",
      "66\n"
     ]
    }
   ],
   "source": [
    "answer_embeddings = process_user_query(user_query, filepath) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see how the most valuable to the \"Revenue\" request cells were left in the table.\n",
    "\n",
    "Answer was prompted to be in JSON format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Total Revenue\": [\n",
      "{\n",
      "\"period\": \"12 Months Ended Dec. 31, 2023\",\n",
      "\"value\": 8971,\n",
      "\"sheet\": \"NOW-US, IS FY'23\",\n",
      "\"cell\": \"C14\"\n",
      "},\n",
      "{\n",
      "\"period\": \"12 Months Ended Dec. 31, 2022\",\n",
      "\"value\": 7245,\n",
      "\"sheet\": \"NOW-US, IS FY'23\",\n",
      "\"cell\": \"D14\"\n",
      "},\n",
      "{\n",
      "\"period\": \"12 Months Ended Dec. 31, 2021\",\n",
      "\"value\": 5896,\n",
      "\"sheet\": \"NOW-US, IS FY'23\",\n",
      "\"cell\": \"E14\"\n",
      "}\n",
      "]\n",
      "---------------------------------------------------\n",
      "\"Total Revenue\": [\n",
      "{\n",
      "\"period\": \"12 Months Ended Dec. 31, 2023\",\n",
      "\"value\": 8971,\n",
      "\"sheet\": \"NOW-US, IS FY'23\",\n",
      "\"cell\": \"C14\"\n",
      "},\n",
      "{\n",
      "\"period\": \"12 Months Ended Dec. 31, 2022\",\n",
      "\"value\": 7245,\n",
      "\"sheet\": \"NOW-US, IS FY'23\",\n",
      "\"cell\": \"D14\"\n",
      "},\n",
      "{\n",
      "\"period\": \"12 Months Ended Dec. 31, 2021\",\n",
      "\"value\": 5896,\n",
      "\"sheet\": \"NOW-US, IS FY'23\",\n",
      "\"cell\": \"E14\"\n",
      "}\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "for ans in answer_embeddings:\n",
    "    print(json_to_string(ans))\n",
    "    print(\"---------------------------------------------------\")\n",
    "    print(ans)\n",
    "    json_string = ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Total Revenue': {'period': {'12 Months Ended Dec. 31, 2023', '12 Months Ended Dec. 31, 2021', '12 Months Ended Dec. 31, 2022'}, 'value': {5896, 8971, 7245}, 'sheet': {\"NOW-US, IS FY'23\"}, 'cell': {'C14', 'D14', 'E14'}}}\n"
     ]
    }
   ],
   "source": [
    "data = json.loads('{' + json_string + '}')\n",
    "\n",
    "transformed_dict = {}\n",
    "for header, items in data.items():\n",
    "    transformed_dict[header] = {\n",
    "        \"period\": {item[\"period\"] for item in items},\n",
    "        \"value\": {item[\"value\"] for item in items},\n",
    "        \"sheet\": {item[\"sheet\"] for item in items},\n",
    "        \"cell\": {item[\"cell\"] for item in items}\n",
    "    }\n",
    "print(transformed_dict)\n",
    "# print(json.dumps(transformed_dict, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see how the filtered table looks like. Window size was set to 1, so the most similar cells and their neighors \n",
    "are in the filtered excel.\n",
    "\n",
    "Then this table was given to the llm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/sample_original.png\" alt=\"filtered table\" style=\"width: 600px;\"/>\n",
    "<img src=\"images/sample_filtered.png\" alt=\"filtered table\" style=\"width: 400px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The embeddings work great and scale well for large tables. However, for small tables, if you put the whole context to llm, \n",
    "it will do great as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_user_query_full_table(user_query, table_path):\n",
    "    queries_formatted, filtered_query = get_formatted_quiries(user_query)\n",
    "    embed_quiries(queries_formatted)\n",
    "\n",
    "    query_answers_list = []\n",
    "\n",
    "    answer = AnswerCall(\"\")\n",
    "    answer.load_table(table_path)\n",
    "\n",
    "    for query in filtered_query.queries:\n",
    "        print(f'{query =}')\n",
    "        answer.query =  UserMessage(query)\n",
    "        answer.respond()\n",
    "        query_answers_list.append(answer.highlighted_json)\n",
    "       \n",
    "    return query_answers_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the same query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query = \"Revenue\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtered_query.queries = ['Total Revenue']\n",
      "query ='Total Revenue'\n"
     ]
    }
   ],
   "source": [
    "answer_full_table = process_user_query_full_table(user_query, filepath) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Total Revenue\": [\n",
      "{\n",
      "\"period\": \"12 Months Ended Dec. 31, 2023\",\n",
      "\"value\": 8971,\n",
      "\"sheet\": \"NOW-US, IS FY'23\",\n",
      "\"cell\": \"B14\"\n",
      "},\n",
      "{\n",
      "\"period\": \"12 Months Ended Dec. 31, 2022\",\n",
      "\"value\": 7245,\n",
      "\"sheet\": \"NOW-US, IS FY'23\",\n",
      "\"cell\": \"C14\"\n",
      "},\n",
      "{\n",
      "\"period\": \"12 Months Ended Dec. 31, 2021\",\n",
      "\"value\": 5896,\n",
      "\"sheet\": \"NOW-US, IS FY'23\",\n",
      "\"cell\": \"D14\"\n",
      "}\n",
      "]\n",
      "---------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for ans in answer_full_table:\n",
    "    print(json_to_string(ans))\n",
    "    print(\"---------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try another query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query = \"Give me other other income and expenses\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtered_query.queries = ['Other Income', 'Other Expenses']\n",
      "query ='Other Income'\n",
      "query ='Other Expenses'\n"
     ]
    }
   ],
   "source": [
    "answer = process_user_query_full_table(user_query, filepath) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Other Income\": [\n",
      "{\n",
      "\"period\": \"12 Months Ended Dec. 31, 2023\",\n",
      "\"value\": -56,\n",
      "\"sheet\": \"NOW-US, IS FY'23\",\n",
      "\"cell\": \"C28\"\n",
      "},\n",
      "{\n",
      "\"period\": \"12 Months Ended Dec. 31, 2022\",\n",
      "\"value\": -38,\n",
      "\"sheet\": \"NOW-US, IS FY'23\",\n",
      "\"cell\": \"D28\"\n",
      "},\n",
      "{\n",
      "\"period\": \"12 Months Ended Dec. 31, 2021\",\n",
      "\"value\": -28,\n",
      "\"sheet\": \"NOW-US, IS FY'23\",\n",
      "\"cell\": \"E28\"\n",
      "}\n",
      "]\n",
      "---------------------------------------------------\n",
      "\"Other Expenses\": [\n",
      "{\n",
      "\"period\": \"12 Months Ended Dec. 31, 2023\",\n",
      "\"value\": -56,\n",
      "\"sheet\": \"NOW-US, IS FY'23\",\n",
      "\"cell\": \"C28\"\n",
      "},\n",
      "{\n",
      "\"period\": \"12 Months Ended Dec. 31, 2022\",\n",
      "\"value\": -38,\n",
      "\"sheet\": \"NOW-US, IS FY'23\",\n",
      "\"cell\": \"D28\"\n",
      "},\n",
      "{\n",
      "\"period\": \"12 Months Ended Dec. 31, 2021\",\n",
      "\"value\": -28,\n",
      "\"sheet\": \"NOW-US, IS FY'23\",\n",
      "\"cell\": \"E28\"\n",
      "}\n",
      "]\n",
      "---------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for ans in answer:\n",
    "    print(json_to_string(ans))\n",
    "    print(\"---------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/sample_original_other.png\" alt=\"filtered table\" style=\"width: 600px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try big cap table!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_table_filepath = 'tutorial_data/complex_sheet.xlsx'\n",
    "generate_embeddings(big_table_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query = \"Revenue\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtered_query.queries = ['Total Revenue']\n",
      "filtered excel for tutorial_data/complex_sheet.xlsx is being created at filtered_table.xlsx\n",
      "291\n"
     ]
    }
   ],
   "source": [
    "answer_big_table = process_user_query(user_query, big_table_filepath) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Total Revenue\": [\n",
      "{\n",
      "\"period\": \"2021-12-31\",\n",
      "\"value\": 5750.5021,\n",
      "\"sheet\": \"IS\",\n",
      "\"cell\": \"I16\"\n",
      "},\n",
      "{\n",
      "\"period\": \"2022-12-31\",\n",
      "\"value\": 6250.94676,\n",
      "\"sheet\": \"IS\",\n",
      "\"cell\": \"J16\"\n",
      "},\n",
      "{\n",
      "\"period\": \"2023-12-31\",\n",
      "\"value\": 8251.11151666667,\n",
      "\"sheet\": \"IS\",\n",
      "\"cell\": \"K16\"\n",
      "},\n",
      "{\n",
      "\"period\": \"2024-12-31\",\n",
      "\"value\": 10298.9533333333,\n",
      "\"sheet\": \"IS\",\n",
      "\"cell\": \"L16\"\n",
      "},\n",
      "{\n",
      "\"period\": \"2025-12-31\",\n",
      "\"value\": 15220.02,\n",
      "\"sheet\": \"IS\",\n",
      "\"cell\": \"M16\"\n",
      "},\n",
      "{\n",
      "\"period\": \"2026-12-31\",\n",
      "\"value\": 21190.02,\n",
      "\"sheet\": \"IS\",\n",
      "\"cell\": \"N16\"\n",
      "}\n",
      "]\n",
      "---------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for ans in answer_big_table:\n",
    "    print(json_to_string(ans))\n",
    "    print(\"---------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see how embeddings and filtering left only cells relevant to the income and their neighbors within\n",
    "some window.\n",
    "\n",
    "Next question is how to represent this extracted data to feed llm. Although CSV works better than the original table,\n",
    "it still uses a lot of space for empty cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/complex_original.png\" alt=\"filtered table\" style=\"width: 800px;\"/>\n",
    "<img src=\"images/complex_filtered.png\" alt=\"filtered table\" style=\"width: 800px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai-env2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
